{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/input.txt\",'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length 1115394\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text length {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42]\n"
     ]
    }
   ],
   "source": [
    "# Character to Integer\n",
    "ctoi = {ch:i for i,ch in enumerate(chars)}\n",
    "# Integer to Character\n",
    "itoc = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "\n",
    "encode = lambda string: [ctoi[c] for c in string]\n",
    "decode = lambda list: ''.join([itoc[i] for i in list])\n",
    "\n",
    "print(encode(\"Hello World\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 train loss 4.7676, test loss 4.7677\n",
      "Step 300 train loss 2.8381, test loss 2.8538\n",
      "Step 600 train loss 2.5531, test loss 2.5811\n",
      "Step 900 train loss 2.4967, test loss 2.5151\n",
      "Step 1200 train loss 2.4878, test loss 2.5086\n",
      "Step 1500 train loss 2.4677, test loss 2.4946\n",
      "Step 1800 train loss 2.4695, test loss 2.4961\n",
      "Step 2100 train loss 2.4707, test loss 2.4871\n",
      "Step 2400 train loss 2.4645, test loss 2.4892\n",
      "Step 2700 train loss 2.4736, test loss 2.4920\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# HyperParams\n",
    "block_size = 8\n",
    "batch_size = 32\n",
    "max_iters = 3000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "eval_iters = 200 \n",
    "# Reproducibility\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "def get_bath(split):\n",
    "    data = train_data if split == \"train\" else test_data\n",
    "    ix = torch.randint( len(data) - block_size, (batch_size,)  )\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_bath(\"train\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "\n",
    "    for split in [\"train\",\"test\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_bath(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) # (V, V)\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "        # B = batch, C = context, \n",
    "        # idx is (B, , C)\n",
    "        logits = self.token_embedding_table(idx) # (B, , C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # predictions\n",
    "            logits, loss = self(idx) #model call\n",
    "            logits = logits[:,-1,:] # (B,C)\n",
    "            probs = F.softmax(logits, dim = -1) # (B,C)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) # Probability sample\n",
    "            idx = torch.cat((idx, idx_next), dim = 1) # Concat\n",
    "        return idx\n",
    "    \n",
    "\n",
    "model = BigramModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        ltr = losses[\"train\"]\n",
    "        ltst = losses[\"test\"]\n",
    "        print(f\"Step {iter} train loss {ltr:.4f}, test loss {ltst:.4f}\")\n",
    "\n",
    "    xb, yb = get_bath(\"train\")\n",
    "\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Ber I t:\n",
      "Prins,\n",
      "Is\n",
      "\n",
      "BURCEd he whindssurt w!\n",
      "RGo t wand y.\n",
      "Fioumeatto! as,\n",
      "HAUSuse heyeshean iatenn po iowe, mbengnd s, te t hisploushount, hintall?\n",
      "ANouthof\n",
      "ts ban ts omy RCILLave malldece f t.\n",
      "ORLI'tt g;ZASe stowl' t is he s as n my RWALI, uren, k de ishathesharou ore yome\n",
      "\n",
      "Whouthareloreavery d thee.\n",
      "NG t erethest m k tindorende s ceke\n",
      "OUThery w'd looriscater a t t s m VEdw HELO:\n",
      "O:\n",
      "He vere beer angon\n",
      "PONT:\n",
      "\n",
      "KINatooBechen n t st witimbout gl othof JutyomiShe lides Ivimusthin t sw rs tofigh hob\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype = torch.long, device = device)\n",
    "print(decode(\n",
    "    m.generate(context, max_new_tokens=500)[0].tolist()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
